# Methods

This section explains the methods used in this research.

## Local sensitivity analysis

Local sensitivity analysis was performed to assess the effect of each of the main 6 plant biochemical and biophysical variables on the PRISMA image bands. In the local sensitivity analysis simulation is performed by keeping all the variables constant at their determined fixed or default values except the parameter of interest. This way the effect of a specific parameter on the simulated spectra can be assessed. In this research the plant parameters $C_{ab}$, $C_{w}$, $C_{m}$, $LAI_{s}$, $CD$ and $SD$ were varied each 15 times (Table (\@ref(tab:tsvaried))), while keeping the rest of the variables at their default values (Table (\@ref(tab:tsfixed))). The default and varied values were chosen based on the literature (e.g. @darvishzadeh2019mapping; @laurent2011inversion; @schlerf2012vegetation) where similar RTM method used to simulate reflectance for Spruce trees.

Table \@ref(tab:tsvaried) shows the 6 parameters that were varied, their units, minimum and maximum values. Each parameter was varied 15 times, meaning 15 different spectra were simulated for each variable.

```{r tsvaried, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("C:\\Users\\zavud\\Desktop\\msc_thesis\\thesis\\tables\\varied_params_INFORM.R")
knitr::kable(var_df, caption = "INFORM Parameters varied in local sensitivity analysis (each parameter were varied 15 times)",
             escape = FALSE, booktabs = TRUE) |>
        kableExtra::kable_styling(latex_options = "HOLD_position", full_width = T) |>
        kableExtra::column_spec(1, width = "8cm")
```

\newpage

Table \@ref(tab:tsfixed) shows the determined default values for each INFORM parameter that were kept during the sensitivity simulation while one of the parameter was varied (Table \@ref(tab:tsvaried)).

```{r tsfixed, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("C:\\Users\\zavud\\Desktop\\msc_thesis\\thesis\\tables\\fixed_params_INFORM.R")
knitr::kable(fixed_df, caption = "INFORM Parameters that were kept constant while one parameter was varied at a time",
             escape = FALSE, booktabs = TRUE) |>
        kableExtra::kable_styling(latex_options = "HOLD_position", full_width = T) |>
        kableExtra::column_spec(1, width = "8cm")
```

*Solar zenith angle* and *Sun-sensor azimuth angle* were calculated based on the PRISMA image acquisition parameters (date, lat/long etc.) using the *solar position calculator* at https://www.esrl.noaa.gov/gmd/grad/solcalc/azel.html.

RTM models PROSPECT5, 4SAIL and FLIM were coupled (INFORM) in order to simulate canopy reflectance. Simulations were carried out using the *ccrtm* package [@ccrtm] in *R* [@r]. The default soil spectra provided by the the *ccrtm* package [@ccrtm] was used for the simulations. Spectral resampling was performed in order to resample the INFORM output spectra (1nm resolution) into PRISMA image bands. For spectral resampling the *R* package *hsdar* [@hsdar] was utilized.

## RTM simulation (INFORM)

PROSPECT5, 4SAIL and FLIM RTM models were coupled (INFORM) to simulate forest canopy reflectance based on different values of plant biophysical and biochemical parameters. The 6 parameters that were mentioned in the previous chapter were varied and spectra was simulated based on each combination of these variables. The number of combinations increase exponentially, which in turn requires increased computational power. Therefore, the trade-off must be taken into account between computational power or time and accurate simulation.

Different authors suggest different number of LUT size for RTM simulation. For example, @danner2021efficient mention that LUT size of minimum 50,000 is recommended. @ali2020machine and @darvishzadeh2019mapping created a LUT size of 100,000 and 500,000 respectively.

In this research, LUT size of 316,800 was created based on each combination of different plant biophysical and biochemical parameters. The range of the varied parameters and parameters that were kept constant were determined based on the suggestions of the studies that were mentioned in the previous chapter. These studies used similar methods to simulate canopy reflectance for mainly Spruce forests/trees.

Table \@ref(tab:tinformfull) shows the variables that were used to simulate forest canopy parameters. Table \@ref(tab:tinformfull) also contains information about the range of the values and how many times each parameter was varied.

\newpage

```{r tinformfull, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("C:\\Users\\zavud\\Desktop\\msc_thesis\\thesis\\tables\\full_params_inform.R")
knitr::kable(inform_full, caption = "Range of full input parameters that were used to create a LUT size of 316800",
             escape = FALSE, booktabs = TRUE) |>
        kableExtra::kable_styling(latex_options = "HOLD_position", full_width = T) |>
        kableExtra::column_spec(1, width = "8cm")
```

All simulations were performed using the library *ccrtm* [@ccrtm] in *R* programming language [@r] using the most recent version 4.1.0. Generating a LUT size of 316,800 is an expensive process from a computational standpoint (depending on how much computer resources and time are available this might change). Also, all simulations are independent of each other, meaning simulation of one spectra has no effect on the other, as every simulated spectra is simulated based on a different combination of parameters. These two factors make the generation of such a large LUT good candidate for parallel computation. Therefore, the software packages *doParallel* [@doparallel] and *foreach* [@foreach] were utilized for parallel computation (using all the available cores) in *R* programming language [@r]. This significantly reduced the computational time. All of the simulations were computed on a Lenovo Thinkpad E480 running under Windows 10 operating system with a processor Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz, 2001 Mhz, 4 Core(s), 8 logical processor(s). 

## Spectral resampling

The output of INFORM simulations have 1nm spectral resolution within the range of 400nm-2500nm and needs to be spectrally resampled to PRISMA image bands. In this research, the spectral response function of the PRISMA image was used. Band center wavelengths and full width half maximum values were extracted from the PRISMA image metadata and used for spectral resampling. For spectral resampling, the *R* package *hsdar* [@hsdar] was utilized.

## Statistics of simulated data and PRISMA image

Statistical information such as standard deviation and mean were calculated for the simulated (and resampled to PRISMA bands) data and all the pixels of the PRISMA image within the study area. Pixels that are out of the study area boundary were masked out. Then, average spectra in the LUT (synthetic database) and PRISMA image (only study area) were compared to each other. LUT contains 316,800 simulated spectra, the number of pixels within the study area in the PRISMA image is only 95517. Statistical information were extracted using the libraries in the *tidyverse* package [@tidyverse] and the plots for visualization were produced using *ggplot2* [@ggplot2].

## Gaussian noise

Simulated reflectance data usually do not contain any noise. This is, however, not the case with remote sensing data as they are commonly found to contain various types of noise [@rivera2017hyperspectral]. In this study, 3% Gaussian noise was added to each simulated spectra in the LUT in order to make the simulated data more similar to the real remote sensing data. In order to assess the effect of adding 3% Gaussian noise to the simulated data, one spectra from the LUT and one pixel from the PRISMA image were randomly picked and plotted. 

## Defining training, validation and testing sets

The data in the LUT was divided into training, validation and testing sets. Model building and training will be done using only the training set. Validation set will be used to validate the model (e.g. assessing the impact of different hyper-parameters) and the performance of the final model will be tested using the testing set. This step is important because it will allow us to monitor whether the model can generalize to the data (e.g. testing set) it was not trained on.

First, the full data set was shuffled and about 20% of the data was randomly sampled and assigned to validation and testing sets (10% validation, 10% testing sets). Random sampling ensures that there is no any pattern contained in any of the divided data sets.

## Data processing

First, the simulated canopy reflectance in the training data set was normalized and standardized using the Equation \@ref(eq:norm):

\begin{equation}
Band_{n_{scaled}}\ =\ \frac{Band_n\ -\ \mu_{Band_n}}{\sigma_{Band_n}}
(\#eq:norm)
\end{equation}

Here $Band_{n}$ refers to the reflectance values in the $n$th simulated band and $\mu_{Band_n}$ and $\sigma_{Band_n}$ are mean and standard deviation of the reflectance values in the $n$th simulated band. $Band_{n_{scaled}}$ is a transformed version of $Band_{n}$ that has a mean of 0 and standard deviation of 1. This step ensures that all simulated bands have the same mean and standard deviation.

Data normalization and standardization were only performed using training data set. Mean and standard deviation of the training set were then used to transform the validation and testing data sets.

## Principal Component Analysis (PCA)

Hyperspectral remote sensing data can contain many highly correlated bands. Dimensionality reduction techniques can be efficiently used to reduce the dimensions of hyperspectral remote sensing data. Benefits of reducing the dimensions of simulated data in plant biophysical variable retrieval studies have been demonstrated [@danner2021efficient; @rivera2017hyperspectral]. In this study, one of the most commonly used DR technique Principal Component Analysis (PCA) was performed. In general, PCA tries to capture as much variation as possible with smaller number variables compared to the original data. PCA produces new variables called Principal Components and each Principal Component (PC) contains certain amount of variation available in the original data. Typically first PC contains the most variation, the second PC contains the second most variation and so on [@bro2014principal].

Like in the processing step, PCA was only applied to the training data and the PCA result in the training data was used to transform the validation and testing sets. Cumulative sum of the variations the PCs contain was calculated in order to assess the proportion of the variation that can be explained with fewer variables than the original data (LUT). PCA and data processing performed using the package *recipes* [@recipes] in *tidymodels* [@tidymodels]. 

## Artificial Neural Networks (ANN)

Considering the fact that we have relatively large number of training examples, non-linear relationship between the input variables (image bands or PCs) and target variables (biophysical and biochemical variables), many different modern and optimization algorithms developed that can learn various types of non-linear relationships, and finally availability of the optimized open source software packages and support, Artificial Neural Network was chosen as a training model in this study.

Deep Neural Networks (DNN) is a specialized name for Artificial Neural Networks. DNN are also called Deep Feedforward Networks. Feedfoward network algorithm refers to an algorithm that tries to use the input example data $x$ to learn a function $f()$ that approximates the output variable $y$ by adjusting the weights variable $\theta$ [@goodfellow2016deep]:

\begin{equation}
y\ =\ f\left(x;\ \theta\right)
(\#eq:feed)
\end{equation}

These algorithms are called networks due to the fact that they usually consists of multiple functions connected to each other with networks. Neural Networks are typically composed of multiple layers, such as input, hidden and output layers. Input layer is typically the training examples and output layer is the target variable (e.g. variable to predict). Hidden layers are in between input and output layers and different functions can be applied to different hidden layers [@goodfellow2016deep]. For example, the Equation \@ref(eq:dnn) shows a function $f(x)$ that is formed by three hidden layers:

\begin{equation}
f\left(x\right)\ =\ f^{\left(3\right)}\left(f^{\left(2\right)}\left(f^{\left(1\right)}\left(x\right)\right)\right)
(\#eq:dnn)
\end{equation}

In the Equation \@ref(eq:dnn), $f^{(1)}$, $f^{(2)}$ and $f^{(3)}$ are the first, second and third layers, respectively. During the learning process, the neural network model is shown the output variables $y$ of corresponding input variables $x$ and the job of the hidden layers is to figure out how to match the target variable $y$ as closely as possible [@goodfellow2016deep].

In this research, two neural network models were built. The first model was trained using only 5 PCs as input variables, and the second neural network was trained using simulated 231 PRISMA bands. The aim of building two neural network models is to compare the performance of a neural network using only 5 PCs to a neural network that uses the original 231 simulated PRISMA bands to predict the output variables.

### Cost function

Choosing an appropriate cost function is an important part of building neural networks model. Essentially, cost function is what the neural network tries to minimize after each iteration. The cost function mean squared error (MSE) is the most widely used cost function for neural network models when the target variable is continuous [@allaire2018deep]. 

In this study, MSE was chosen to be the cost function of the neural network models. The Equation \@ref(eq:mse) shows how the cost function MSE is defined:

\begin{equation}
MSE\ =\ \frac{1}{N}\sum_{i\ =\ 1}^n\left(y_i\ -\ f\left(x_i;\ \theta\right)\right)^2
(\#eq:mse)
\end{equation}

In the Equation \@ref(eq:mse), $N$ is the number of examples, $y_{i}$ is the $i$th true value and $f(x_{i}; \theta)$ is the predicted $i$th value. $x_{i}$ refers to the input parameter of $i$th example, and $\theta$ typically refers to weight term $w$ and a bias term $b$.

Apart from MSE, mean absolute error (MAE) was calculated as a metric and monitored during the training. MAE is defined as shown in the Equation \@ref(eq:mae):

\begin{equation}
MAE\ =\ \frac{1}{N}\sum_{i\ =\ 1}^n\left|y_i\ -\ f\left(x_i;\ \theta\right)\right|
(\#eq:mae)
\end{equation}

### Optimizer algorithm

In this research, Adam optimizer [@kingma2014adam] was applied to the neural network model. Before explaining what Adam does, it is important to visit the Stochastic gradient descent (SGD) algorithm.

Stochastic gradient descent is a very important algorithm used to build neural network models. SGD is used to update the learned weight and bias parameters $\theta$. Let's assume that we have a model that tries to minimize the cost function $J(\theta)$

\begin{equation}
J\left(\theta\right)\ =\ \frac{1}{m}\sum_{i\ =\ 1}^mL\left(x^i,\ y^i,\ \theta\right)
(\#eq:cs)
\end{equation}

where L is the amount of loss for the $i$th example. Then, we compute the gradient as shown in the Equation \@ref(eq:derivative):

\begin{equation}
\nabla_{\theta}J\left(\theta\right)\ =\ \frac{1}{m}\sum_{i\ =\ 1}^m\nabla_{\theta}L\left(x^i,\ y^i,\ \theta\right)
(\#eq:derivative)
\end{equation}

Finally, we can update the weight and bias parameters within the term $\theta$:

\begin{equation}
\theta\ \leftarrow\ \theta\ -\ \epsilon\\\nabla_{\theta}J\left(\theta\right)\
(\#eq:gd)
\end{equation}

In the Equation \@ref(eq:gd) $\epsilon$ is called learning rate and needs to be tuned. The learning rate parameter $\epsilon$ is a very important hyperparameter for neural network and it is considered to be the most difficult hyperparameter to tune [@goodfellow2016deep].

Usually, some of the directions in the parameter space can have a significant effect on the cost and some of them may not have any effect at all. Adaptive learning algorithms can efficiently solve this problem. One of the most commonly used adaptive learning algorithm is Adam [@kingma2014adam]. Essentially, Adam can be thought as a combination of RMSProp [@hinton2012neural] and Momentum [@polyak1964some] algorithms with minor differences. In the RMSProp algorithm, exponentially decaying averages are used to mitigate the problem of extreme updates. This helps the model converge more rapidly and less sensitive to extreme cases. The Momentum algorithm uses additional parameter called velocity $v$ apart from learning rate $\epsilon$. And during the gradient descent update, the velocity term $v$ is additionally taken into consideration. The Adam algorithm implements first and second order moment terms. Unlike RMSProp, Adam also implements correction for the bias of first and second order moments [@goodfellow2016deep]. @goodfellow2016deep can be referred to for more detailed explanation of how the algorithms RMSProp, Momentum and Adam are implemented.

The main drawback of Adam is that now there are more hyperparameters to tune compared to simpler algorithms such as SGD. The Adam optimizer requires the hyperparameters step size $\epsilon$, exponential decay rates $p1$ and $p2$ and a constant $\delta$. In this study, the suggested default value of 0.001 was used for the step size term $\epsilon$. $p1$ and $p2$ were set to 0.9 and 0.999 respectively (suggested values). The constant term $\delta$ is $10^{-8}$. Different most commonly used learning rate values ($lr$) were tested. The optimum learning rate value (specific to this study) was found to be 0.0001.

### Regularization

Regularization is a technique that prevents the problem of overfitting to the training data by adding a penalty term to the cost function. It is an important technique because it can help the trained model to generalize better to the data that it has never seen. In this study, training and validation loss were monitored during the training phase. After some iteration, the model started to fit to the training data too well and the performance of the model on the validation was poorer. Therefore, $L^{2}$ norm regularization was applied in order to overcome the problem of overfitting. 

$L^{2}$ regularization is a penalty term that is directly added to the defined cost function. In general, given a cost function $J$, the $L^{2}$ penalty is implemented as shown in the Equation \@ref(eq:l2gen).

\begin{equation}
\tilde{J}(\theta) = J\left(\theta\right)\ +\ \lambda w^Tw
(\#eq:l2gen)
\end{equation}

In the Equation \@ref(eq:l2gen) $\tilde{J}$ is called regularized cost function and it tries to minimize the cost $J$ and the regularization term added together. The term $\lambda$ is $L^{2}$ regularization factor and it controls the amount of penalty that is added. For example, when $\lambda = 0$ there is no any constraint added and $\tilde{J} = J$. The larger the $\lambda$, the more penalty we add, and therefore the flexibility of the weights to fit to the training data is more limited. The $L^{2}$ regularization does not affect bias term $b$ and only regularizes weight term $w$. $\lambda$ is another hyperparamter that needs to be tuned. In this study, most commonly used values (0.1, 0.01, 0.001 etc.) were tested and $\lambda = 0.0001$ was found to work well in terms of improving the generalizability of the model to the validation set.

The cost function in this study was updated from the Equation \@ref(eq:mse) to the Equation \@ref(eq:msereg):

\begin{equation}
\tilde{MSE}\ =\ \frac{1}{N}\sum_{i\ =\ 1}^n\left(y_i\ -\ f\left(x_i;\ \theta\right)\right)^2 +\ 0.0001 w^Tw
(\#eq:msereg)
\end{equation}

Here, $\tilde{MSE}$ is the regularized cost function that our model tries to minimize.

### Early stopping

Early stopping is a simple technique that monitors the loss and it halts the training when the model starts to overfit to the training data or when it does not improve its accuracy on the validation set over iterations. In this study, validation loss was monitored during the training after each iteration. The parameter *patience* controls when to stop the training and it was set to 50 in this research. This means that if there is no improvement on the validation loss during the last 50 iterations of the training, the training process must stop. This helps with the overfitting problem as well as it halts the unnecessary training steps (if there is no any improvement after each iteration).

### Activation function

In neural networks, the units of the layers are activated by using activation functions. In this study, rectified linear unit activation (ReLU) function was utilized. The units in the hidden layers receive a vector $x$ from the previous layer, and transforms it using a weight term $W$ and a bias term $b$ as follows:

\begin{equation}
z\ =\ W^Tx\ +\ b
(\#eq:z)
\end{equation}

And then, we can use a non-linear activation function ReLU to activate $z$:

\begin{equation}
g\left(z\right)\ =\ \max\left\{0,\ z\right\}
(\#eq:relu)
\end{equation}

As we can see, ReLU gives a value of 0 when $z$ is smaller than 0, and it returns $z$ otherwise. ReLU is undefined at $z = 0$.

### Weight initialization

Neural network training is an iterative process and initial weights need to be given. @goodfellow2016deep indicate that, the initial weight values can sometimes have a large impact on the neural network performance and depending on how the initial weights are defined the neural network moedl may not converge at all. In this research the He initialzation [@he2015delving] method was applied. This initialization technique was designed to work with NN that make use of the ReLU activation functions. He initialization technique draws initial weights randomly from normal distribution, where the mean $\mu = 0$, and standard deviation $\sigma = \sqrt{\frac{2}{n_{l}}}$. Here, $n_{l}$ refers to the number of nodes in the previous layer $l - 1$, that is connected to the nodes in the current layer $l$.


































